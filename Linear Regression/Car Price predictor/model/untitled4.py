# -*- coding: utf-8 -*-
"""Untitled4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1A5pgEQnyLbOVRM3W1hApURS53Qnzsl-8
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

car = pd.read_csv('quikr_car.csv')

"""
1. .head()
2. .info()
3. .unique()

OneHotEncoder(categories = ohe.categories) is trying to manually specify categories to be used for encoding. However, since ohe.categories does not have an underscore, it seems to refer to a user-set attribute, which is not what you want here.
OneHotEncoder(categories = ohe.categories_) correctly uses the learned categories from a previously fitted OneHotEncoder instance stored in ohe. The categories_ attribute contains the actual categories that were present during fitting.
Using categories_ ensures that the new transformer uses the same categories as the ones learned during the fitting process. This is crucial when transforming new data to ensure consistency with the training data, and it is why using categories_ resolves your issue 4.

Remember to always fit your transformers on the training data and then use the learned attributes (like categories_) to transform both the training data and any new data (like test data). This ensures that the encoding is consistent and matches what the model was trained on, preventing errors like "Found unknown categories".
"""

car.head() #returns first n rows

car.shape

car.info() #summary #see price, year etc must be int, not object

car['year'].unique() # 1. its an object, 2. contains non-integer

car['Price'].unique() # 1. its an object, 2. contains non-integer 3. have to remove commas

car['kms_driven'].unique() # 1. its an object, 2. contains non-integer 3. contains commas and 'kms'

car['fuel_type'].unique() #4. contains nan values

"""# Data cleaning
- year has many non-years value
- year object to int
- price has Ask for Price
- Price object to int
- kms_driven has kms with integers
- kms_driven object to int
- kms_driven has nan values
- fuel_type has nan values
- keep first 3 words of name
"""

backup = car.copy()

car = car[car['year'].str.isnumeric()] # car['year'].str.isnumeric() -->true or false

car['year'] = car['year'].astype(int)

car.info()

car = car[car['Price'] != "Ask For Price"]

car['Price'] = car['Price'].str.replace(',','').astype(int)

car.info()

car['kms_driven']

car['kms_driven'] = car['kms_driven'].str.split(" ").str.get(0).str.replace(',','')

car = car[car['kms_driven'].str.isnumeric()]

car['kms_driven'] = car['kms_driven'].astype(int)

car.info()

car['fuel_type'].unique()

car = car[~ car['fuel_type'].isna()] # excluding all the cols that includes nan

car['fuel_type'].unique()

# Keeping first words of the name
car['name'] = car['name'].str.split(" ").str.slice(0,3).str.join(' ')

car = car.reset_index(drop = True)

car.info()

car.describe()

# as its an odd kinda value
car[car['Price'] > 6e6] # car price above 60 lacs

car = car[ car['Price'] < 6e6]

car.reset_index(drop = True)

car.to_csv('clean_car.csv')

X = car.drop(columns = 'Price')
y = car['Price']

X

y

car.isnull().sum()

"""# Model"""

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import make_column_transformer
from sklearn.pipeline import make_pipeline

ohe = OneHotEncoder()
ohe.fit(X[['name','company','fuel_type']])

column_trans = make_column_transformer((OneHotEncoder(categories = ohe.categories_),['name','company','fuel_type']),
                                       remainder = 'passthrough')

lr = LinearRegression()

pipe = make_pipeline(column_trans, lr)

pipe.fit(X_train, y_train)

y_pred = pipe.predict(X_test)

y_pred

r2_score(y_test, y_pred)

scores = []
for i in range(1000):
  X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2, random_state = i)
  lr = LinearRegression()
  pipe = make_pipeline(column_trans, lr)
  pipe.fit(X_train, y_train)
  y_pred = pipe.predict(X_test)
  scores.append(r2_score(y_test,y_pred))
value_of_highest_index = np.argmax(scores) # index, where the highest value is

X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2, random_state = value_of_highest_index)

lr = LinearRegression()

pipe = make_pipeline(column_trans, lr)
pipe.fit(X_train, y_train)
y_pred = (pipe.predict(X_test))

y_pred

import pickle
pickle.dump(pipe, open('LinearRegressionModell.pkl','wb'))

pipe.predict(pd.DataFrame([['Maruti Suzuki Swift', 'Maruti', 2011, 100,'Petrol']],columns=['name','company','year','kms_driven','fuel_type']))